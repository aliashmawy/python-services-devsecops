# -*- coding: utf-8 -*-
"""main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y6flypOGaiwPGuoCk3FT0e6wMEf7O2dY
"""

import os
import tempfile
import shutil
import json
import numpy as np
import time
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field

# FastAPI and other necessary imports
from fastapi import FastAPI, UploadFile, File, HTTPException
from google import genai
from google.genai import types
from google.genai.errors import ServerError
from pypdf import PdfReader
from docx import Document
from numpy.linalg import norm


# =================================================================
# --- 1. PYDANTIC DATA STRUCTURES (Models) ---
# =================================================================

# Sub-models for CV structure
class ProjectEntry(BaseModel):
    project_name: str = Field(description="The name of the project.")
    summary: str = Field(description="A brief summary including the goal and main technologies.")
    technologies_used: List[str] = Field(description="A list of 3-5 core technical tools or frameworks used.")

class CertificationEntry(BaseModel):
    name: str = Field(description="The name of the certification or course.")
    issuer: str = Field(description="The issuing organization.")
    year_or_date: Optional[str] = Field(None, description="The year or date obtained.")

class EducationEntry(BaseModel):
    degree: str = Field(description="The name of the degree.")
    institution: str = Field(description="The name of the university or institution.")
    year_range: str = Field(description="The start and end year or graduation year.")

class ExperienceEntry(BaseModel):
    title: str = Field(description="The job title.")
    company: str = Field(description="The company name.")
    years_or_duration: str = Field(description="The duration of the role.")
    summary: str = Field(description="A brief summary of the role and key achievements.")

class Resume(BaseModel):
    """The complete structured data model for a resume."""
    full_name: str = Field(description="The candidate's full name.")
    email: str = Field(description="The primary email address.")
    phone: Optional[str] = Field(None, description="The phone number, if available.")
    total_experience_years: float = Field(description="The candidate's total professional experience in years.")
    key_skills: List[str] = Field(description="A list of the 8-10 most important technical and soft skills.")
    experience: List[ExperienceEntry] = Field(description="A list of all professional work experiences.")
    education: List[EducationEntry] = Field(description="A list of all educational achievements.")
    projects: List[ProjectEntry] = Field(description="A list of 2-5 most relevant projects.")
    certifications: List[CertificationEntry] = Field(description="A list of all professional certifications and major online courses.")

# API Response Model for Ranging
class RankedCandidate(BaseModel):
    """Represents a single candidate's score and key data for the ranking output."""
    full_name: str = Field(..., description="The candidate's full name.")
    # MODIFIED: Changed back to float, representing 0.00 to 100.00
    match_score: float = Field(..., description="Semantic match score (0-100) against the JD.")
    total_experience_years: float = Field(..., description="Total professional experience extracted from the CV.")
    top_skills: List[str] = Field(..., description="The top 3 key skills extracted from the CV.")
    cv_filename: str = Field(..., description="The filename of the processed CV for easy reference.")


# =================================================================
# --- 2. CORE LOGIC FUNCTIONS ---
# =================================================================

def convert_pdf_to_text(file_path: str) -> str:
    """Extracts text from a PDF file."""
    text = ""
    try:
        reader = PdfReader(file_path)
        for page in reader.pages:
            text += page.extract_text() or ""
        return text
    except Exception as e:
        print(f"ERROR: PDF extraction failed for {os.path.basename(file_path)}: {e}")
        return ""

def convert_docx_to_text(file_path: str) -> str:
    """Extracts text from a DOCX file."""
    text = ""
    try:
        document = Document(file_path)
        for paragraph in document.paragraphs:
            text += paragraph.text + "\n"
        return text
    except Exception as e:
        print(f"ERROR: DOCX extraction failed for {os.path.basename(file_path)}: {e}")
        return ""

def get_text_from_file(file_path: str) -> str:
    """Helper to call the correct text extraction based on file type."""
    file_path_lower = file_path.lower()

    # 1. Check for .PDF
    if file_path_lower.endswith('.pdf'):
        return convert_pdf_to_text(file_path)

    # 2. Check for .DOCX
    elif file_path_lower.endswith(('.docx', '.doc')):
        return convert_docx_to_text(file_path)

    # 3. Check for .TXT (Handling reading errors)
    elif file_path_lower.endswith('.txt'):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"ERROR: TXT reading failed for {os.path.basename(file_path)}: {e}")
            return ""

    # 4. Handle other/unsupported files
    print(f"ERROR: Unsupported file extension: {os.path.basename(file_path)}")
    return ""

def parse_cv_text_with_gemini(cv_text: str, resume_model=Resume, max_retries=3) -> Optional[Resume]:
    """Sends CV text to the Gemini API with retries for server errors."""
    client = genai.Client()
    system_instruction = (
        "You are an expert CV parser. Your task is to accurately extract all specified fields "
        "from the provided resume text and return the data as a single JSON object. "
        "Calculate the 'total_experience_years' accurately. Do not include any commentary or explanation outside the JSON."
    )
    config = types.GenerateContentConfig(
        response_mime_type="application/json",
        response_schema=resume_model,
    )

    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[system_instruction, "RESUME TEXT:\n\n" + cv_text],
                config=config,
            )
            json_data = json.loads(response.text)
            return resume_model.model_validate(json_data)
        except ServerError as e:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
            else:
                print(f"ERROR: ServerError on parsing (Attempt {attempt + 1}): {e}")
                return None
        except Exception as e:
            print(f"ERROR: JSON or Validation failed during parsing: {e}")
            print(f"RESPONSE TEXT (might be partial or non-JSON): {response.text[:500] if 'response' in locals() else 'No response object.'}")
            return None
    return None

def get_embedding(text: str) -> List[float]:
    """
    Generates a vector embedding for a given text using the Gemini API.
    """
    client = genai.Client()

    try:
        response = client.models.embed_content(
            model="gemini-embedding-001",
            contents=[text],
            config=types.EmbedContentConfig(task_type="RETRIEVAL_DOCUMENT"),
        )
        return list(response.embeddings[0].values)

    except Exception as e:
        print(f"âŒ Error during embedding call: {e}")
        return []

def calculate_cosine_similarity(vector_a: List[float], vector_b: List[float]) -> float:
    """Calculates the cosine similarity between two vectors."""
    A = np.array(vector_a)
    B = np.array(vector_b)

    if norm(A) == 0 or norm(B) == 0:
        return 0.0

    cosine = np.dot(A, B) / (norm(A) * norm(B))
    return float(cosine)


# =================================================================
# --- 3. FASTAPI APPLICATION SETUP AND ENDPOINTS ---
# =================================================================

app = FastAPI(
    title="Gemini CV Ranking API",
    description="Calculates semantic match score for multiple CVs against a single Job Description.",
    version="1.0.0"
)

# 1. HEALTH CHECK ENDPOINT
@app.get("/")
def read_root():
    """Simple health check endpoint."""
    return {"status": "ok", "api_version": app.version, "endpoint": "/rank"}


# 2. RANKING ENDPOINT
@app.post("/rank", response_model=List[RankedCandidate])
async def rank_candidates(
    jd_file: UploadFile = File(..., description="The Job Description (PDF, DOCX, TXT)"),
    cv_files: List[UploadFile] = File(..., description="A list of Candidate CVs (PDF, DOCX)")
):
    """
    Accepts one Job Description and multiple CVs, then ranks the candidates by semantic score.
    """

    if not cv_files:
        raise HTTPException(status_code=400, detail="Must upload at least one CV file.")

    ranking_results: List[RankedCandidate] = []

    with tempfile.TemporaryDirectory() as temp_dir:

        # ----------------------------------------------------
        # Step 1: Process JD ONCE (Reference Vector)
        # ----------------------------------------------------
        jd_path = os.path.join(temp_dir, jd_file.filename)
        with open(jd_path, "wb") as buffer:
            shutil.copyfileobj(jd_file.file, buffer)

        jd_text = get_text_from_file(jd_path)
        if not jd_text:
             raise HTTPException(status_code=400, detail="Could not extract text from Job Description.")

        jd_embedding = get_embedding(jd_text)
        if not jd_embedding:
            raise HTTPException(status_code=500, detail="Failed to generate embedding for Job Description.")


        # ----------------------------------------------------
        # Step 2: Loop Through and Process All CVs
        # ----------------------------------------------------

        for cv_file in cv_files:
            cv_filename = cv_file.filename
            cv_path = os.path.join(temp_dir, cv_filename)

            # Save CV file temporarily
            with open(cv_path, "wb") as buffer:
                shutil.copyfileobj(cv_file.file, buffer)

            try:
                # 2a. Convert CV to Text
                cv_text = get_text_from_file(cv_path)
                if not cv_text:
                    print(f"Skipping {cv_filename}: Text extraction failed.")
                    continue

                # 2b. Parse CV to Structured Data
                parsed_data = parse_cv_text_with_gemini(cv_text)
                if not parsed_data:
                    print(f"Skipping {cv_filename}: Gemini parsing failed.")
                    ranking_results.append(RankedCandidate(
                        full_name=cv_filename,
                        match_score=0.0,
                        total_experience_years=0.0,
                        top_skills=["Parsing Failed"],
                        cv_filename=cv_filename
                    ))
                    continue

                # 2c. Embed CV Text
                cv_embedding = get_embedding(cv_text)
                if not cv_embedding:
                    print(f"Skipping {cv_filename}: Embedding failed.")
                    ranking_results.append(RankedCandidate(
                        full_name=parsed_data.full_name,
                        match_score=0.0,
                        total_experience_years=parsed_data.total_experience_years,
                        top_skills=["Embedding Failed"],
                        cv_filename=cv_filename
                    ))
                    continue

                # 2d. Calculate Score and Format
                match_score_raw = calculate_cosine_similarity(jd_embedding, cv_embedding)

                # MODIFIED: Convert to percentage and round to 2 decimals
                formatted_score = round(match_score_raw * 100, 2)

                # 2e. Store Result
                ranking_results.append(RankedCandidate(
                    full_name=parsed_data.full_name,
                    match_score=formatted_score, # Now a float between 0.00 and 100.00
                    total_experience_years=parsed_data.total_experience_years,
                    top_skills=parsed_data.key_skills[:3],
                    cv_filename=cv_filename
                ))

            except Exception as e:
                print(f"Error processing {cv_filename}: {e}")

        # ----------------------------------------------------
        # Step 3: Sort and Return the Ranking
        # ----------------------------------------------------

        # Sort by match_score (float) in descending order
        ranking_results.sort(key=lambda x: x.match_score, reverse=True)

        return ranking_results